{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888007f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44782159",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/arsalan/UW/og_fhwa_kcm_transit_2021start - General/Analysis on ORCA data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2786b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023 = pd.read_csv('2023-04_orca_boardings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1314226",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "ORCA_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023['card_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd525d0",
   "metadata": {},
   "source": [
    "In July, about 397,000 people rode King County Metro transit on an average weekday citywide, about 66,000 of them on BRT lines. More than 66,000 rode Sound Transit Express buses every day throughout their whole network, too. Trains, light rail, and streetcars made up 8 percent of commutes, the survey found (curbed.com, 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a82f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023['stop_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35705c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023['stop_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a1977",
   "metadata": {},
   "source": [
    "Based on the analysis on the APC data it should be around 7000 bus stops in King County. Stop_id column has NAN values but is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023['device_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023['txn_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023['business_date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a192d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'card_id' and count unique 'stop_id' values within each group\n",
    "bus_usage_count = ORCA_2023.groupby('card_id')['stop_code'].nunique()\n",
    "# Create a new DataFrame to display the results\n",
    "bus_usage_df = pd.DataFrame({'card_id': bus_usage_count.index, 'Number_of_stops_Used': bus_usage_count.values})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(bus_usage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68ce1c",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "We use the groupby method to group the DataFrame by the \"card_id\" column.\n",
    "Then, we apply the nunique function to count the unique \"stop_id\" values within each group.\n",
    "We create a new DataFrame (bus_usage_df) to display the results, with \"card_id\" and \"Number_of_Buses_Used\" as the column names.\n",
    "Finally, we print the resulting DataFrame, which will show the number of buses each person used.\n",
    "This code will give you a DataFrame where each row represents a unique \"card_id\" along with the corresponding number of buses used by that person.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'card_id' and count 'stop_id' values within each group\n",
    "bus_stops_count = ORCA_2023.groupby('card_id')['stop_code'].count()\n",
    "\n",
    "# Create a new DataFrame to display the results\n",
    "bus_stops_df = pd.DataFrame({'card_id': bus_stops_count.index, 'Number_of_buses_Used': bus_stops_count.values})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(bus_stops_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc505b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'card_id' and 'business_date', then count unique 'stop_id' values within each group\n",
    "unique_bus_stops_count = ORCA_2023.groupby(['card_id', 'business_date'])['stop_code'].nunique().reset_index()\n",
    "\n",
    "# Rename the 'stop_id' column to 'Number_of_Unique_Stops_Used'\n",
    "unique_bus_stops_count.rename(columns={'stop_code': 'Number_of_Unique_Stops_Used'}, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(unique_bus_stops_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'card_id' and 'business_date', then count 'stop_id' values within each group\n",
    "bus_stops_count = ORCA_2023.groupby(['card_id', 'business_date'])['stop_code'].count().reset_index()\n",
    "\n",
    "# Rename the 'stop_id' column to 'Number_of_Stops_Used'\n",
    "bus_stops_count.rename(columns={'stop_code': 'Number_of_Stops_Used'}, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(bus_stops_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4060d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'card_id' and count unique 'business_date' values within each group\n",
    "bus_days_count = ORCA_2023.groupby('card_id')['business_date'].nunique().reset_index()\n",
    "\n",
    "# Rename the 'business_date' column to 'Number_of_Days_Used'\n",
    "bus_days_count.rename(columns={'business_date': 'Number_of_Days_Used'}, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(bus_days_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'business_date' and calculate the sum of 'Number_of_Stops_Used' for each date\n",
    "daily_stops_sum = bus_stops_count.groupby('card_id')['Number_of_Stops_Used'].sum().reset_index()\n",
    "\n",
    "# Rename the 'Number_of_Stops_Used' column to 'Total_Stops_Used_Per_Day'\n",
    "daily_stops_sum.rename(columns={'Number_of_Stops_Used': 'Total_Stops_Used_Per_Month'}, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame with the total stops used per day\n",
    "print(daily_stops_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'daily_stops_sum' DataFrame with 'bus_days_count' on 'card_id' using an inner join\n",
    "merged_data = pd.merge(daily_stops_sum, bus_days_count, on='card_id', how='inner')\n",
    "\n",
    "# Calculate the average number of bus stops in each month for each user\n",
    "merged_data['Average_Stops_Per_Day_Per_Month'] = merged_data['Total_Stops_Used_Per_Month'] / merged_data['Number_of_Days_Used']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(merged_data[['card_id', 'Average_Stops_Per_Day_Per_Month']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'card_id' and 'stop_id', then count the occurrences of each 'stop_id'\n",
    "stop_usage_count = ORCA_2023.groupby(['card_id', 'stop_code']).size().reset_index(name='Stop_Frequency')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(stop_usage_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of stops used for each card_id\n",
    "total_stops_used = ORCA_2023.groupby('card_id')['stop_code'].count().reset_index()\n",
    "total_stops_used.rename(columns={'stop_code': 'Total_Stops_Used'}, inplace=True)\n",
    "\n",
    "# Merge the total stops used with the stop_usage_count DataFrame\n",
    "stop_usage_count = pd.merge(stop_usage_count, total_stops_used, on='card_id')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(stop_usage_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stop_usage_count DataFrame to a CSV file\n",
    "stop_usage_count.to_csv('stop_usage_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stops_used = ORCA_2023.groupby('card_id')['stop_id'].nunique().reset_index()\n",
    "total_stops_used.rename(columns={'stop_id': 'Total_Stops_Used_unique'}, inplace=True)\n",
    "\n",
    "# Merge the total stops used with the stop_usage_count DataFrame\n",
    "stop_usage_count = pd.merge(stop_usage_count, total_stops_used, on='card_id')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(stop_usage_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4edc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stop_usage_count DataFrame to a CSV file\n",
    "stop_usage_count.to_csv('stop_usage_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd67bce",
   "metadata": {},
   "source": [
    "CHANGING THE COORDINATION SYSTEM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the State Plane coordinate system for Washington State (EPSG:2926)\n",
    "source_crs = pyproj.CRS.from_epsg(2926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3aeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target coordinate system to WGS84 (EPSG:4326)\n",
    "target_crs = pyproj.CRS.from_epsg(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef14542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer to convert from source to target CRS\n",
    "transformer = pyproj.Transformer.from_crs(source_crs, target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0982e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation to the coordinates in the data frame\n",
    "ORCA_2023['Latitude'], ORCA_2023['Longitude'] = transformer.transform(ORCA_2023['device_lat'].values, ORCA_2023['device_lng'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCA_2023.to_csv(\"2023-04_orca_boardings_new_coordinates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553ccc8",
   "metadata": {},
   "source": [
    "The above projection did not work as it is not using the same coordinates as APC project. The values should just be devided by 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff73847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'device_lat' column to the desired format\n",
    "ORCA_2023['device_lat'] = ORCA_2023['device_lat'] / 1000000\n",
    "ORCA_2023['device_lng'] = ORCA_2023['device_lng'] / 1000000\n",
    "# Display the DataFrame with the updated 'device_lat' values\n",
    "print(ORCA_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a35aee",
   "metadata": {},
   "source": [
    "Adding locations to 'stop_usage_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9897fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'device_lat' and 'device_lng' columns from 'ORCA_2023' into 'stop_usage_count' by 'stop_id'\n",
    "stop_usage_count_with_location = pd.merge(stop_usage_count, ORCA_2023[['stop_id', 'device_lat', 'device_lng']], on='stop_id', how='left')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(stop_usage_count_with_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Assuming 'stop_usage_count' and 'ORCA_2023' are your DataFrames\n",
    "\n",
    "# Create a SQLite database and connect to it\n",
    "db_engine = create_engine('sqlite:///mydatabase.db')\n",
    "\n",
    "# Write DataFrames to the database\n",
    "stop_usage_count.to_sql('stop_usage_count_table', db_engine, if_exists='replace', index=False)\n",
    "ORCA_2023.to_sql('ORCA_2023_table', db_engine, if_exists='replace', index=False)\n",
    "\n",
    "# Perform the merge in the database using SQL\n",
    "query = \"\"\"\n",
    "SELECT a.*, b.device_lat, b.device_lng\n",
    "FROM stop_usage_count_table AS a\n",
    "LEFT JOIN ORCA_2023_table AS b\n",
    "ON a.stop_id = b.stop_id;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a DataFrame\n",
    "merged_data = pd.read_sql_query(query, db_engine)\n",
    "\n",
    "# Close the database connection\n",
    "db_engine.dispose()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93fe15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (0.14.0)\r\n",
      "Requirement already satisfied: numpy in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from folium) (1.21.5)\r\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from folium) (2.11.3)\r\n",
      "Requirement already satisfied: branca>=0.6.0 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from folium) (0.6.0)\r\n",
      "Requirement already satisfied: requests in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from folium) (2.28.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from jinja2>=2.9->folium) (2.0.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from requests->folium) (1.26.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from requests->folium) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from requests->folium) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shakibanaderian/opt/anaconda3/lib/python3.9/site-packages (from requests->folium) (3.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install folium\n",
    "import folium\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c1fb15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/zynvgz3502n7wqtzvnrpjnj40000gn/T/ipykernel_28667/342241639.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_23 = pd.read_csv('2023-04_orca_boardings.csv')\n"
     ]
    }
   ],
   "source": [
    "df_23 = pd.read_csv('2023-04_orca_boardings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990ad0fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_23 = df_23.sort_values(by=['business_date','card_id'], ascending=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8b3816",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            txn_id                boarding_guid  txn_type_id  card_id  \\\n256999   195660046   1536003r-70-46-6428623fc2e           66        2   \n272054   195709760   155140d0-70-60-64287e453b8           66        4   \n329901   195906358   1308607q-70-66-6428d2d5fce           66        4   \n330115   195907290   1308607q-70-66-6428d2d5fce           84        4   \n312589   195845680   165400a3-70-89-6428b977c22           66        9   \n...            ...                          ...          ...      ...   \n2420764  213969342   1627607s-70-62-644ec353bea           66  3577027   \n2410688  213910784   13065018-70-43-644e904a1a2           66  3577863   \n2415592  213938742   1286409v-70-38-644eabd0630           66  3577981   \n5216060  214045842  1284301e-70-183-644ef8d330c           66  3577981   \n2441357  214089128  1293809o-70-282-644f1a6e7c0           66  3578298   \n\n         passenger_type_id  passenger_count  product_id business_date  \\\n256999                   1                1      1003.0    2023-04-01   \n272054                   1                1      1003.0    2023-04-01   \n329901                   1                1      1003.0    2023-04-01   \n330115                   1                1      1003.0    2023-04-01   \n312589                   1                1       102.0    2023-04-01   \n...                    ...              ...         ...           ...   \n2420764                  1                1         NaN    2023-04-30   \n2410688                  1                1         NaN    2023-04-30   \n2415592                  1                1         NaN    2023-04-30   \n5216060                  1                1         NaN    2023-04-30   \n2441357                  1                1         NaN    2023-04-30   \n\n         device_id   device_dtm_pacific  ...  participant_group_id  \\\n256999     15360.0  2023-04-01 09:56:31  ...                1240.0   \n272054     15514.0  2023-04-01 11:56:05  ...               29124.0   \n329901     13086.0  2023-04-01 17:56:53  ...               29124.0   \n330115     15704.0  2023-04-01 17:58:24  ...               29124.0   \n312589     16540.0  2023-04-01 16:08:39  ...                   NaN   \n...            ...                  ...  ...                   ...   \n2420764    16276.0  2023-04-30 12:36:51  ...                   NaN   \n2410688    13065.0  2023-04-30 08:59:06  ...                   NaN   \n2415592    12864.0  2023-04-30 10:56:32  ...                   NaN   \n5216060    12843.0  2023-04-30 16:25:07  ...                   NaN   \n2441357    12938.0  2023-04-30 18:48:30  ...                   NaN   \n\n            stop_id stop_code  ticket_internal_nbr  osfa_cents  ceffv_cents  \\\n256999   96403200.0     37040                  307         275          275   \n272054   96408808.0     55583                  307         275          275   \n329901   96440468.0     55778                  218         300          300   \n330115   96408992.0     56031                  307         275          275   \n312589   96400124.0      2672                  307         275          275   \n...             ...       ...                  ...         ...          ...   \n2420764  96409380.0       570                  307         275          275   \n2410688  96440440.0      1108                  218         300          225   \n2415592  96440504.0    990001                  218         325          325   \n5216060  96440452.0       501                  218         300          300   \n2441357  96440572.0     99903                  218         350          225   \n\n         total_journey_fare_cents linked_journey_fare_cents  \\\n256999                        275                       275   \n272054                        275                       275   \n329901                        575                       300   \n330115                        575                       300   \n312589                        275                       275   \n...                           ...                       ...   \n2420764                       275                       275   \n2410688                       225                       225   \n2415592                       325                       325   \n5216060                       300                       300   \n2441357                       225                       225   \n\n         epurse_equivalent_cents       load_start_dtm  \n256999                       275  2023-04-02 08:52:37  \n272054                       275  2023-04-02 08:52:37  \n329901                       157  2023-04-02 08:52:37  \n330115                       143  2023-04-02 08:52:37  \n312589                       275  2023-04-02 08:52:37  \n...                          ...                  ...  \n2420764                      275  2023-05-02 11:03:28  \n2410688                      225  2023-05-02 11:03:28  \n2415592                      325  2023-05-02 11:03:28  \n5216060                      300  2023-05-02 11:03:28  \n2441357                      225  2023-05-02 11:03:28  \n\n[5229140 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txn_id</th>\n      <th>boarding_guid</th>\n      <th>txn_type_id</th>\n      <th>card_id</th>\n      <th>passenger_type_id</th>\n      <th>passenger_count</th>\n      <th>product_id</th>\n      <th>business_date</th>\n      <th>device_id</th>\n      <th>device_dtm_pacific</th>\n      <th>...</th>\n      <th>participant_group_id</th>\n      <th>stop_id</th>\n      <th>stop_code</th>\n      <th>ticket_internal_nbr</th>\n      <th>osfa_cents</th>\n      <th>ceffv_cents</th>\n      <th>total_journey_fare_cents</th>\n      <th>linked_journey_fare_cents</th>\n      <th>epurse_equivalent_cents</th>\n      <th>load_start_dtm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256999</th>\n      <td>195660046</td>\n      <td>1536003r-70-46-6428623fc2e</td>\n      <td>66</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>15360.0</td>\n      <td>2023-04-01 09:56:31</td>\n      <td>...</td>\n      <td>1240.0</td>\n      <td>96403200.0</td>\n      <td>37040</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>272054</th>\n      <td>195709760</td>\n      <td>155140d0-70-60-64287e453b8</td>\n      <td>66</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>15514.0</td>\n      <td>2023-04-01 11:56:05</td>\n      <td>...</td>\n      <td>29124.0</td>\n      <td>96408808.0</td>\n      <td>55583</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>329901</th>\n      <td>195906358</td>\n      <td>1308607q-70-66-6428d2d5fce</td>\n      <td>66</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>13086.0</td>\n      <td>2023-04-01 17:56:53</td>\n      <td>...</td>\n      <td>29124.0</td>\n      <td>96440468.0</td>\n      <td>55778</td>\n      <td>218</td>\n      <td>300</td>\n      <td>300</td>\n      <td>575</td>\n      <td>300</td>\n      <td>157</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>330115</th>\n      <td>195907290</td>\n      <td>1308607q-70-66-6428d2d5fce</td>\n      <td>84</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>15704.0</td>\n      <td>2023-04-01 17:58:24</td>\n      <td>...</td>\n      <td>29124.0</td>\n      <td>96408992.0</td>\n      <td>56031</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>575</td>\n      <td>300</td>\n      <td>143</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>312589</th>\n      <td>195845680</td>\n      <td>165400a3-70-89-6428b977c22</td>\n      <td>66</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>102.0</td>\n      <td>2023-04-01</td>\n      <td>16540.0</td>\n      <td>2023-04-01 16:08:39</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96400124.0</td>\n      <td>2672</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2420764</th>\n      <td>213969342</td>\n      <td>1627607s-70-62-644ec353bea</td>\n      <td>66</td>\n      <td>3577027</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>16276.0</td>\n      <td>2023-04-30 12:36:51</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96409380.0</td>\n      <td>570</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>2410688</th>\n      <td>213910784</td>\n      <td>13065018-70-43-644e904a1a2</td>\n      <td>66</td>\n      <td>3577863</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>13065.0</td>\n      <td>2023-04-30 08:59:06</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440440.0</td>\n      <td>1108</td>\n      <td>218</td>\n      <td>300</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>2415592</th>\n      <td>213938742</td>\n      <td>1286409v-70-38-644eabd0630</td>\n      <td>66</td>\n      <td>3577981</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>12864.0</td>\n      <td>2023-04-30 10:56:32</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440504.0</td>\n      <td>990001</td>\n      <td>218</td>\n      <td>325</td>\n      <td>325</td>\n      <td>325</td>\n      <td>325</td>\n      <td>325</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>5216060</th>\n      <td>214045842</td>\n      <td>1284301e-70-183-644ef8d330c</td>\n      <td>66</td>\n      <td>3577981</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>12843.0</td>\n      <td>2023-04-30 16:25:07</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440452.0</td>\n      <td>501</td>\n      <td>218</td>\n      <td>300</td>\n      <td>300</td>\n      <td>300</td>\n      <td>300</td>\n      <td>300</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>2441357</th>\n      <td>214089128</td>\n      <td>1293809o-70-282-644f1a6e7c0</td>\n      <td>66</td>\n      <td>3578298</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>12938.0</td>\n      <td>2023-04-30 18:48:30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440572.0</td>\n      <td>99903</td>\n      <td>218</td>\n      <td>350</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n  </tbody>\n</table>\n<p>5229140 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d679612",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            txn_id                boarding_guid  txn_type_id  card_id  \\\n256999   195660046   1536003r-70-46-6428623fc2e           66        2   \n272054   195709760   155140d0-70-60-64287e453b8           66        4   \n329901   195906358   1308607q-70-66-6428d2d5fce           66        4   \n330115   195907290   1308607q-70-66-6428d2d5fce           84        4   \n312589   195845680   165400a3-70-89-6428b977c22           66        9   \n...            ...                          ...          ...      ...   \n2420764  213969342   1627607s-70-62-644ec353bea           66  3577027   \n2410688  213910784   13065018-70-43-644e904a1a2           66  3577863   \n2415592  213938742   1286409v-70-38-644eabd0630           66  3577981   \n5216060  214045842  1284301e-70-183-644ef8d330c           66  3577981   \n2441357  214089128  1293809o-70-282-644f1a6e7c0           66  3578298   \n\n         passenger_type_id  passenger_count  product_id business_date  \\\n256999                   1                1      1003.0    2023-04-01   \n272054                   1                1      1003.0    2023-04-01   \n329901                   1                1      1003.0    2023-04-01   \n330115                   1                1      1003.0    2023-04-01   \n312589                   1                1       102.0    2023-04-01   \n...                    ...              ...         ...           ...   \n2420764                  1                1         NaN    2023-04-30   \n2410688                  1                1         NaN    2023-04-30   \n2415592                  1                1         NaN    2023-04-30   \n5216060                  1                1         NaN    2023-04-30   \n2441357                  1                1         NaN    2023-04-30   \n\n         device_id   device_dtm_pacific  ...  participant_group_id  \\\n256999     15360.0  2023-04-01 09:56:31  ...                1240.0   \n272054     15514.0  2023-04-01 11:56:05  ...               29124.0   \n329901     13086.0  2023-04-01 17:56:53  ...               29124.0   \n330115     15704.0  2023-04-01 17:58:24  ...               29124.0   \n312589     16540.0  2023-04-01 16:08:39  ...                   NaN   \n...            ...                  ...  ...                   ...   \n2420764    16276.0  2023-04-30 12:36:51  ...                   NaN   \n2410688    13065.0  2023-04-30 08:59:06  ...                   NaN   \n2415592    12864.0  2023-04-30 10:56:32  ...                   NaN   \n5216060    12843.0  2023-04-30 16:25:07  ...                   NaN   \n2441357    12938.0  2023-04-30 18:48:30  ...                   NaN   \n\n            stop_id stop_code  ticket_internal_nbr  osfa_cents  ceffv_cents  \\\n256999   96403200.0     37040                  307         275          275   \n272054   96408808.0     55583                  307         275          275   \n329901   96440468.0     55778                  218         300          300   \n330115   96408992.0     56031                  307         275          275   \n312589   96400124.0      2672                  307         275          275   \n...             ...       ...                  ...         ...          ...   \n2420764  96409380.0       570                  307         275          275   \n2410688  96440440.0      1108                  218         300          225   \n2415592  96440504.0    990001                  218         325          325   \n5216060  96440452.0       501                  218         300          300   \n2441357  96440572.0     99903                  218         350          225   \n\n         total_journey_fare_cents linked_journey_fare_cents  \\\n256999                        275                       275   \n272054                        275                       275   \n329901                        575                       300   \n330115                        575                       300   \n312589                        275                       275   \n...                           ...                       ...   \n2420764                       275                       275   \n2410688                       225                       225   \n2415592                       325                       325   \n5216060                       300                       300   \n2441357                       225                       225   \n\n         epurse_equivalent_cents       load_start_dtm  \n256999                       275  2023-04-02 08:52:37  \n272054                       275  2023-04-02 08:52:37  \n329901                       157  2023-04-02 08:52:37  \n330115                       143  2023-04-02 08:52:37  \n312589                       275  2023-04-02 08:52:37  \n...                          ...                  ...  \n2420764                      275  2023-05-02 11:03:28  \n2410688                      225  2023-05-02 11:03:28  \n2415592                      325  2023-05-02 11:03:28  \n5216060                      300  2023-05-02 11:03:28  \n2441357                      225  2023-05-02 11:03:28  \n\n[5229140 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txn_id</th>\n      <th>boarding_guid</th>\n      <th>txn_type_id</th>\n      <th>card_id</th>\n      <th>passenger_type_id</th>\n      <th>passenger_count</th>\n      <th>product_id</th>\n      <th>business_date</th>\n      <th>device_id</th>\n      <th>device_dtm_pacific</th>\n      <th>...</th>\n      <th>participant_group_id</th>\n      <th>stop_id</th>\n      <th>stop_code</th>\n      <th>ticket_internal_nbr</th>\n      <th>osfa_cents</th>\n      <th>ceffv_cents</th>\n      <th>total_journey_fare_cents</th>\n      <th>linked_journey_fare_cents</th>\n      <th>epurse_equivalent_cents</th>\n      <th>load_start_dtm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256999</th>\n      <td>195660046</td>\n      <td>1536003r-70-46-6428623fc2e</td>\n      <td>66</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>15360.0</td>\n      <td>2023-04-01 09:56:31</td>\n      <td>...</td>\n      <td>1240.0</td>\n      <td>96403200.0</td>\n      <td>37040</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>272054</th>\n      <td>195709760</td>\n      <td>155140d0-70-60-64287e453b8</td>\n      <td>66</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>15514.0</td>\n      <td>2023-04-01 11:56:05</td>\n      <td>...</td>\n      <td>29124.0</td>\n      <td>96408808.0</td>\n      <td>55583</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>329901</th>\n      <td>195906358</td>\n      <td>1308607q-70-66-6428d2d5fce</td>\n      <td>66</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>13086.0</td>\n      <td>2023-04-01 17:56:53</td>\n      <td>...</td>\n      <td>29124.0</td>\n      <td>96440468.0</td>\n      <td>55778</td>\n      <td>218</td>\n      <td>300</td>\n      <td>300</td>\n      <td>575</td>\n      <td>300</td>\n      <td>157</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>330115</th>\n      <td>195907290</td>\n      <td>1308607q-70-66-6428d2d5fce</td>\n      <td>84</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1003.0</td>\n      <td>2023-04-01</td>\n      <td>15704.0</td>\n      <td>2023-04-01 17:58:24</td>\n      <td>...</td>\n      <td>29124.0</td>\n      <td>96408992.0</td>\n      <td>56031</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>575</td>\n      <td>300</td>\n      <td>143</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>312589</th>\n      <td>195845680</td>\n      <td>165400a3-70-89-6428b977c22</td>\n      <td>66</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>102.0</td>\n      <td>2023-04-01</td>\n      <td>16540.0</td>\n      <td>2023-04-01 16:08:39</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96400124.0</td>\n      <td>2672</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-04-02 08:52:37</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2420764</th>\n      <td>213969342</td>\n      <td>1627607s-70-62-644ec353bea</td>\n      <td>66</td>\n      <td>3577027</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>16276.0</td>\n      <td>2023-04-30 12:36:51</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96409380.0</td>\n      <td>570</td>\n      <td>307</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>275</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>2410688</th>\n      <td>213910784</td>\n      <td>13065018-70-43-644e904a1a2</td>\n      <td>66</td>\n      <td>3577863</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>13065.0</td>\n      <td>2023-04-30 08:59:06</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440440.0</td>\n      <td>1108</td>\n      <td>218</td>\n      <td>300</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>2415592</th>\n      <td>213938742</td>\n      <td>1286409v-70-38-644eabd0630</td>\n      <td>66</td>\n      <td>3577981</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>12864.0</td>\n      <td>2023-04-30 10:56:32</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440504.0</td>\n      <td>990001</td>\n      <td>218</td>\n      <td>325</td>\n      <td>325</td>\n      <td>325</td>\n      <td>325</td>\n      <td>325</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>5216060</th>\n      <td>214045842</td>\n      <td>1284301e-70-183-644ef8d330c</td>\n      <td>66</td>\n      <td>3577981</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>12843.0</td>\n      <td>2023-04-30 16:25:07</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440452.0</td>\n      <td>501</td>\n      <td>218</td>\n      <td>300</td>\n      <td>300</td>\n      <td>300</td>\n      <td>300</td>\n      <td>300</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n    <tr>\n      <th>2441357</th>\n      <td>214089128</td>\n      <td>1293809o-70-282-644f1a6e7c0</td>\n      <td>66</td>\n      <td>3578298</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2023-04-30</td>\n      <td>12938.0</td>\n      <td>2023-04-30 18:48:30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>96440572.0</td>\n      <td>99903</td>\n      <td>218</td>\n      <td>350</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>225</td>\n      <td>2023-05-02 11:03:28</td>\n    </tr>\n  </tbody>\n</table>\n<p>5229140 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_23['device_lat'] = df_23['device_lat'] / 1000000\n",
    "df_23['device_lng'] = df_23['device_lng'] / 1000000\n",
    "df_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758e1c4f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_23['device_dtm_pacific'] = pd.to_datetime(df_23['device_dtm_pacific'])\n",
    "df_23['business_date'] = pd.to_datetime(df_23['business_date'])\n",
    "df_23['time_of_day'] = df_23['device_dtm_pacific'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b652bb2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_23=df_23[['card_id','business_date','time_of_day','device_lat','device_lng','stop_code','route_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2b27c0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         card_id business_date time_of_day  device_lat  device_lng stop_code  \\\n256999         2    2023-04-01    09:56:31   47.690703 -122.360021     37040   \n272054         4    2023-04-01    11:56:05   47.523868 -122.278888     55583   \n329901         4    2023-04-01    17:56:53   47.560280 -122.292892     55778   \n330115         4    2023-04-01    17:58:24   47.560626 -122.293461     56031   \n312589         9    2023-04-01    16:08:39   47.624075 -122.356790      2672   \n...          ...           ...         ...         ...         ...       ...   \n2420764  3577027    2023-04-30    12:36:51   47.608716 -122.336681       570   \n2410688  3577863    2023-04-30    08:59:06   47.611450 -122.337532      1108   \n2415592  3577981    2023-04-30    10:56:32   47.659875 -122.314194    990001   \n5216060  3577981    2023-04-30    16:25:07   47.602139 -122.331055       501   \n2441357  3578298    2023-04-30    18:48:30   47.445053 -122.296692     99903   \n\n        route_number  \n256999            45  \n272054           106  \n329901        100479  \n330115           106  \n312589           674  \n...              ...  \n2420764           40  \n2410688       100479  \n2415592       100479  \n5216060       100479  \n2441357       100479  \n\n[5229140 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>card_id</th>\n      <th>business_date</th>\n      <th>time_of_day</th>\n      <th>device_lat</th>\n      <th>device_lng</th>\n      <th>stop_code</th>\n      <th>route_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256999</th>\n      <td>2</td>\n      <td>2023-04-01</td>\n      <td>09:56:31</td>\n      <td>47.690703</td>\n      <td>-122.360021</td>\n      <td>37040</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>272054</th>\n      <td>4</td>\n      <td>2023-04-01</td>\n      <td>11:56:05</td>\n      <td>47.523868</td>\n      <td>-122.278888</td>\n      <td>55583</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>329901</th>\n      <td>4</td>\n      <td>2023-04-01</td>\n      <td>17:56:53</td>\n      <td>47.560280</td>\n      <td>-122.292892</td>\n      <td>55778</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>330115</th>\n      <td>4</td>\n      <td>2023-04-01</td>\n      <td>17:58:24</td>\n      <td>47.560626</td>\n      <td>-122.293461</td>\n      <td>56031</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>312589</th>\n      <td>9</td>\n      <td>2023-04-01</td>\n      <td>16:08:39</td>\n      <td>47.624075</td>\n      <td>-122.356790</td>\n      <td>2672</td>\n      <td>674</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2420764</th>\n      <td>3577027</td>\n      <td>2023-04-30</td>\n      <td>12:36:51</td>\n      <td>47.608716</td>\n      <td>-122.336681</td>\n      <td>570</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2410688</th>\n      <td>3577863</td>\n      <td>2023-04-30</td>\n      <td>08:59:06</td>\n      <td>47.611450</td>\n      <td>-122.337532</td>\n      <td>1108</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>2415592</th>\n      <td>3577981</td>\n      <td>2023-04-30</td>\n      <td>10:56:32</td>\n      <td>47.659875</td>\n      <td>-122.314194</td>\n      <td>990001</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>5216060</th>\n      <td>3577981</td>\n      <td>2023-04-30</td>\n      <td>16:25:07</td>\n      <td>47.602139</td>\n      <td>-122.331055</td>\n      <td>501</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>2441357</th>\n      <td>3578298</td>\n      <td>2023-04-30</td>\n      <td>18:48:30</td>\n      <td>47.445053</td>\n      <td>-122.296692</td>\n      <td>99903</td>\n      <td>100479</td>\n    </tr>\n  </tbody>\n</table>\n<p>5229140 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_23=df_23.dropna(subset=['stop_code'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(4994066, 7)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_23.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6160cb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat=df_23.iloc[0]['device_lat']\n",
    "lng=df_23.iloc[0]['device_lng']\n",
    "num_rows = df_23.shape[0]\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494ba82",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_color():\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(random.randint(0, 200), random.randint(0, 200), random.randint(0, 200))\n",
    "\n",
    "\n",
    "df_23 = df_23.dropna(subset=['device_lat','device_lng'])\n",
    "num_rows = df_23.shape[0]\n",
    "date = df_23.iloc[0]['business_date'].date()\n",
    "card=1\n",
    "lat=df_23.iloc[0]['device_lat']\n",
    "lng=df_23.iloc[0]['device_lng']\n",
    "m = folium.Map(location=[lat, lng], zoom_start=12)\n",
    "# for i in range(204900,num_rows):\n",
    "for i in range(num_rows):\n",
    "    lat=df_23.iloc[i]['device_lat']\n",
    "    lng=df_23.iloc[i]['device_lng']\n",
    "    if(df_23.iloc[i]['business_date'].date()==date):\n",
    "        if(df_23.iloc[i]['card_id']==card) and (i>0):\n",
    "            folium.Marker([lat, lng], tooltip=f\"Stop ID: {df_23.iloc[i]['stop_code']}\").add_to(m)\n",
    "            folium.Marker([df_23.iloc[i-1]['device_lat'], df_23.iloc[i-1]['device_lng']], tooltip=f\"Stop ID: {df_23.iloc[i-1]['stop_code']}\").add_to(m)\n",
    "            line = folium.PolyLine(\n",
    "                locations=[[lat, lng], [df_23.iloc[i-1]['device_lat'], df_23.iloc[i-1]['device_lng']]],\n",
    "                color=co,\n",
    "                weight=2,\n",
    "                tooltip=f'Card ID: {card}'\n",
    "            )\n",
    "            line.add_to(m)\n",
    "            m.save(f'map{date}.html')\n",
    "            print(m)\n",
    "        else:\n",
    "            card=df_23.iloc[i]['card_id']\n",
    "            co=random_color()\n",
    "    else:\n",
    "        date = date + timedelta(days=1)\n",
    "        m = folium.Map(location=[lat, lng], zoom_start=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7faa2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_usage_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335cea6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_usage_count.to_csv('stop_usage_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdd799",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859faa1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_232=df_23.sort_values(by=['card_id','business_date'], ascending=[True,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extracting Origin and destinations:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "trip_count = df_23.groupby('card_id')['business_date'].value_counts().reset_index(name='trip_count')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "         card_id business_date  trip_count\n0              1    2023-04-02           2\n1              1    2023-04-04           2\n2              1    2023-04-18           2\n3              1    2023-04-20           2\n4              1    2023-04-24           2\n...          ...           ...         ...\n2187773  3577246    2023-04-29           3\n2187774  3577863    2023-04-30           1\n2187775  3577981    2023-04-30           2\n2187776  3578120    2023-04-29           1\n2187777  3578298    2023-04-30           1\n\n[2187778 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>card_id</th>\n      <th>business_date</th>\n      <th>trip_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2023-04-02</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2023-04-04</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2023-04-18</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2023-04-20</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2023-04-24</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2187773</th>\n      <td>3577246</td>\n      <td>2023-04-29</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2187774</th>\n      <td>3577863</td>\n      <td>2023-04-30</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2187775</th>\n      <td>3577981</td>\n      <td>2023-04-30</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2187776</th>\n      <td>3578120</td>\n      <td>2023-04-29</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2187777</th>\n      <td>3578298</td>\n      <td>2023-04-30</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2187778 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656816\n"
     ]
    },
    {
     "data": {
      "text/plain": "30.022058910913263"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_ones = (trip_count['trip_count'] == 1).sum()\n",
    "print(count_of_ones)\n",
    "count_of_non_ones = (trip_count['trip_count'] != 1).sum()\n",
    "count_of_ones/(count_of_ones+count_of_non_ones)*100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "origin_data = df_23[df_23['time_of_day']>=pd.to_datetime('04:00:00', format='%H:%M:%S').time()].groupby(['card_id', 'business_date'])['stop_code'].first().reset_index()\n",
    "origin_data=origin_data.rename(columns={\"stop_code\":\"first origin (home)\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23[(df_23['time_of_day']<=pd.to_datetime('05:00:00', format='%H:%M:%S').time()) & (df_23['time_of_day']>=pd.to_datetime('04:00:00', format='%H:%M:%S').time())]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23[(df_23['time_of_day']<=pd.to_datetime('04:00:00', format='%H:%M:%S').time()) & (df_23['time_of_day']>=pd.to_datetime('03:00:00', format='%H:%M:%S').time())]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "origin_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_23=df_23.sort_values(by=['card_id','business_date','time_of_day'], ascending=[True,True,True])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card_id          False\n",
      "business_date    False\n",
      "time_of_day      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "nan_exists = df_23[['card_id', 'business_date', 'time_of_day']].isna().any()\n",
    "print(nan_exists)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "taz={}\n",
    "\n",
    "card_id=df_23['card_id'].unique().tolist()\n",
    "n_card_id=df_23['card_id'].nunique()\n",
    "dates=df_23.groupby(['card_id'])['business_date'].unique().to_dict()\n",
    "#times=df_23.groupby(['card_id','business_date'])['time_of_day'].unique()\n",
    "#n_date=df_23.groupby(['card_id'])['business_date'].nunique()\n",
    "#print(n_date[n_date.index==2].iloc[0])\n",
    "print(dates[4])\n",
    "#print(times[times.index==4,'00:00:00'])\n",
    "\n",
    "#for i in range(len(df_23)):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4994066, 7)\n",
      "Not all values in 'stop_code' are numbers.\n",
      "(4853394, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_23.shape)\n",
    "all_numeric = pd.to_numeric(df_23['stop_code'], errors='coerce').notna().all()\n",
    "\n",
    "if all_numeric:\n",
    "    print(\"All values in 'stop_code' are numbers.\")\n",
    "else:\n",
    "    print(\"Not all values in 'stop_code' are numbers.\")\n",
    "\n",
    "df_23 = df_23[pd.to_numeric(df_23['stop_code'], errors='coerce').notna()]\n",
    "print(df_23.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "am4=pd.to_datetime('04:00:00', format='%H:%M:%S').time()\n",
    "am0=pd.to_datetime('00:00:00', format='%H:%M:%S').time()\n",
    "\n",
    "df_23[(df_23['time_of_day']<am4) & (df_23['time_of_day']>am0)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23[df_23['card_id']==74]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23[df_23['card_id']==1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23[df_23['card_id']==2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "taz={}\n",
    "am4=pd.to_datetime('04:00:00', format='%H:%M:%S').time()\n",
    "am0=pd.to_datetime('00:00:00', format='%H:%M:%S').time()\n",
    "\n",
    "for person in card_id:\n",
    "    for index in range(len(dates[person])):\n",
    "        d=dates[person][index]\n",
    "        df = df_23[(df_23['card_id'] == person) & (df_23['business_date'] == d)].reset_index()\n",
    "        df=df[df['time_of_day'] >= am4]\n",
    "        if index < len(dates[person]) - 1:\n",
    "            dd = dates[person][index + 1]\n",
    "            dff = df_23[(df_23['card_id'] == person) & (df_23['business_date'] == dd)].reset_index()\n",
    "            dff = dff[(dff['time_of_day'] < am4) & (dff['time_of_day'] >= am0)]\n",
    "            df = df.append(dff, ignore_index=True)\n",
    "            df = df.reset_index(drop=True)\n",
    "        n = df.shape[0]\n",
    "        if (n==1 or n==0): continue\n",
    "        origin = df['stop_code'].iloc[0]\n",
    "        o = origin\n",
    "        # idx= df.loc[df['time_of_day'] >= am4, 'stop_code'].index[0]\n",
    "        for i in range(n-1):\n",
    "            taz.setdefault(o, [])\n",
    "            tod = df['time_of_day'][i]\n",
    "            time_diff = datetime.datetime.combine(df['business_date'][i+1].date(), df['time_of_day'][i+1]) - datetime.datetime.combine(df['business_date'][i].date(),df['time_of_day'][i])\n",
    "            if time_diff.total_seconds() > 7200 or i+1==n-1:\n",
    "                destination=df['stop_code'][i+1]\n",
    "                taz.setdefault(destination, [])\n",
    "                taz[o].append(destination)\n",
    "                o=destination\n",
    "                if (i+1==n-1): taz[destination].append(origin)\n",
    "    print(person)\n",
    "    # max_length = max(len(v) for v in taz.values())\n",
    "    # for key in taz:\n",
    "    #     taz[key] += [None] * (max_length - len(taz[key]))\n",
    "    # output = pd.DataFrame(taz)\n",
    "    # output.to_excel('output.csv', index=False)\n",
    "    with open('output.json', \"w\") as json_file:\n",
    "         json.dump(taz, json_file, indent=4)\n",
    "\n",
    "# output = pd.DataFrame(taz)\n",
    "# output.to_csv('output.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "         card_id business_date time_of_day  device_lat  device_lng stop_code  \\\n439379         1    2023-04-02    19:24:54   47.611710 -122.324195      3034   \n447746         1    2023-04-02    22:44:02   47.626855 -122.356853      2680   \n679314         1    2023-04-03    23:54:55   47.611960 -122.335771      1110   \n801361         1    2023-04-04    14:09:12   47.701158 -122.355461      5730   \n809699         1    2023-04-04    14:46:02   47.609986 -122.337038      1180   \n...          ...           ...         ...         ...         ...       ...   \n2410688  3577863    2023-04-30    08:59:06   47.611450 -122.337532      1108   \n2415592  3577981    2023-04-30    10:56:32   47.659875 -122.314194    990001   \n5216060  3577981    2023-04-30    16:25:07   47.602139 -122.331055       501   \n5187245  3578120    2023-04-29    21:50:46   47.809686 -122.382485      2727   \n2441357  3578298    2023-04-30    18:48:30   47.445053 -122.296692     99903   \n\n        route_number  \n439379             2  \n447746             2  \n679314            11  \n801361             5  \n809699            10  \n...              ...  \n2410688       100479  \n2415592       100479  \n5216060       100479  \n5187245          196  \n2441357       100479  \n\n[4853394 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>card_id</th>\n      <th>business_date</th>\n      <th>time_of_day</th>\n      <th>device_lat</th>\n      <th>device_lng</th>\n      <th>stop_code</th>\n      <th>route_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>439379</th>\n      <td>1</td>\n      <td>2023-04-02</td>\n      <td>19:24:54</td>\n      <td>47.611710</td>\n      <td>-122.324195</td>\n      <td>3034</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>447746</th>\n      <td>1</td>\n      <td>2023-04-02</td>\n      <td>22:44:02</td>\n      <td>47.626855</td>\n      <td>-122.356853</td>\n      <td>2680</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>679314</th>\n      <td>1</td>\n      <td>2023-04-03</td>\n      <td>23:54:55</td>\n      <td>47.611960</td>\n      <td>-122.335771</td>\n      <td>1110</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>801361</th>\n      <td>1</td>\n      <td>2023-04-04</td>\n      <td>14:09:12</td>\n      <td>47.701158</td>\n      <td>-122.355461</td>\n      <td>5730</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>809699</th>\n      <td>1</td>\n      <td>2023-04-04</td>\n      <td>14:46:02</td>\n      <td>47.609986</td>\n      <td>-122.337038</td>\n      <td>1180</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2410688</th>\n      <td>3577863</td>\n      <td>2023-04-30</td>\n      <td>08:59:06</td>\n      <td>47.611450</td>\n      <td>-122.337532</td>\n      <td>1108</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>2415592</th>\n      <td>3577981</td>\n      <td>2023-04-30</td>\n      <td>10:56:32</td>\n      <td>47.659875</td>\n      <td>-122.314194</td>\n      <td>990001</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>5216060</th>\n      <td>3577981</td>\n      <td>2023-04-30</td>\n      <td>16:25:07</td>\n      <td>47.602139</td>\n      <td>-122.331055</td>\n      <td>501</td>\n      <td>100479</td>\n    </tr>\n    <tr>\n      <th>5187245</th>\n      <td>3578120</td>\n      <td>2023-04-29</td>\n      <td>21:50:46</td>\n      <td>47.809686</td>\n      <td>-122.382485</td>\n      <td>2727</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>2441357</th>\n      <td>3578298</td>\n      <td>2023-04-30</td>\n      <td>18:48:30</td>\n      <td>47.445053</td>\n      <td>-122.296692</td>\n      <td>99903</td>\n      <td>100479</td>\n    </tr>\n  </tbody>\n</table>\n<p>4853394 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_23"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23_timeshift=df_23\n",
    "am4=pd.to_datetime('04:00:00', format='%H:%M:%S').time()\n",
    "\n",
    "def shift_time(row):\n",
    "    if row['time_of_day'] < am4:\n",
    "        row['business_date'] -= pd.DateOffset(days=1)\n",
    "    return row\n",
    "\n",
    "# Apply the time shift separately for each person using groupby\n",
    "df_23_timeshift = df_23_timeshift.apply(lambda row: shift_time(row), axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df_23_timeshift)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_23[df_23['time_of_day']<am4])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23_timeshift[df_23_timeshift['time_of_day']<am4].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23_timeshift[df_23_timeshift['card_id']==62]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "taz={}\n",
    "am4=pd.to_datetime('04:00:00', format='%H:%M:%S').time()\n",
    "am0=pd.to_datetime('00:00:00', format='%H:%M:%S').time()\n",
    "\n",
    "def custom_investigation(group):\n",
    "\n",
    "    n=len(group['time_of_day'])\n",
    "    origin=group['stop_code'].iloc[0]\n",
    "    o = origin\n",
    "    for i in range(n-1):\n",
    "        taz.setdefault(o, [])\n",
    "        time_diff = datetime.datetime.combine(group['business_date'].iloc[i+1].date(), group['time_of_day'].iloc[i+1]) - datetime.datetime.combine(group['business_date'].iloc[i].date(),group['time_of_day'].iloc[i])\n",
    "        if time_diff.total_seconds() > 7200 or i+1==n-1:\n",
    "            destination=group['stop_code'].iloc[i+1]\n",
    "            taz.setdefault(destination, [])\n",
    "            taz[o].append(destination)\n",
    "            o=destination\n",
    "            if (i+1==n-1): taz[destination].append(origin)\n",
    "\n",
    "\n",
    "    return taz\n",
    "\n",
    "result = df_23_timeshift.groupby(['card_id', 'business_date']).apply(custom_investigation)\n",
    "\n",
    "\n",
    "with open('output.json', \"w\") as json_file:\n",
    "     json.dump(taz, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "with open('output.json', 'r') as json_file:\n",
    "    taz = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23[df_23['card_id']==62]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23_timeshift[df_23_timeshift['card_id']==62]\n",
    "pd.set_option('display.max_rows', None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_23_timeshift[df_23_timeshift['card_id']==62]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'35318' in taz['990005']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "8887"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taz)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9043\n"
     ]
    }
   ],
   "source": [
    "print(df_23['stop_code'].nunique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3402251\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for key, values in taz.items():\n",
    "    for value in values:\n",
    "        a+=1\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1, 1), (2, 2), (3, 3), (4, 1), (5, 2))\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "original_list = [1, 2, 2, 3, 3, 3, 4, 5, 5]\n",
    "count_dict = dict(Counter(original_list))\n",
    "unique_tuple = tuple((key, count) for key, count in count_dict.items())\n",
    "print(unique_tuple)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "for key in taz.keys():\n",
    "    count_dict=dict(Counter(taz[key]))\n",
    "    tuplee = tuple((key2, count) for key2, count in count_dict.items())\n",
    "    taz[key]=tuplee"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(('2680', 9),\n ('570', 3),\n ('21740', 1),\n ('450', 56),\n ('22820', 2),\n ('468', 20),\n ('2672', 42),\n ('2670', 1),\n ('600', 14),\n ('575', 20))"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taz['3034'][0:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "with open('output_with_counts.json', \"w\") as json_file:\n",
    "     json.dump(taz, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "6918afd7",
   "metadata": {},
   "source": [
    "Flow analysis:\n",
    "First, I want to exclude passengers who only used one bus stop (unique) in a month. They might have more than one bus stop usage but if all of them are from one bus stop it will not be useful so we filter them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a8725",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the number of times each card_id used the bus\n",
    "usage_counts = ORCA_2023.groupby('card_id')['stop_code'].nunique()\n",
    "print(ORCA_2023[ORCA_2023.card_id==84])\n",
    "\n",
    "# Identify card_ids that used the bus only once\n",
    "card_ids_to_exclude = usage_counts[usage_counts == 1].index\n",
    "print(usage_counts[usage_counts == 0])\n",
    "# Exclude card_ids with usage count 1 from the original dataset\n",
    "filtered_data = ORCA_2023[~ORCA_2023['card_id'].isin(card_ids_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4be881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(card_ids_to_exclude.shape)\n",
    "print(ORCA_2023.shape)\n",
    "print(filtered_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each card_id used the bus\n",
    "usage_counts = ORCA_2023.groupby('card_id')['stop_code'].count()\n",
    "print(usage_counts)\n",
    "# Identify card_ids that used the bus only once\n",
    "card_ids_to_exclude = usage_counts[usage_counts == 0].index\n",
    "print(card_ids_to_exclude.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283496d5",
   "metadata": {},
   "source": [
    "We also have zeros in stop counts (I don't know why). So, I exported usage counts data to excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_counts = ORCA_2023.groupby('card_id')['stop_code'].count()\n",
    "\n",
    "# Convert the usage_counts to a DataFrame for easier export to Excel\n",
    "usage_counts_df = pd.DataFrame({'card_id': usage_counts.index, 'usage_count': usage_counts.values})\n",
    "\n",
    "# Specify the file path including the directory\n",
    "excel_file_path = './usage_counts.xlsx'\n",
    "\n",
    "# Export to Excel\n",
    "usage_counts_df.to_excel(excel_file_path, index=False, sheet_name='UsageCounts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036972f1",
   "metadata": {},
   "source": [
    "I want to exclude zeros now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each card_id used the bus\n",
    "usage_counts = ORCA_2023.groupby('card_id')['stop_code'].count()\n",
    "print(usage_counts)\n",
    "# Identify card_ids that used the bus only once\n",
    "card_ids_to_exclude = usage_counts[usage_counts == 0].index\n",
    "print(card_ids_to_exclude.shape)\n",
    "# Exclude card_ids with usage count 1 from the original dataset\n",
    "filtered_data = filtered_data[~filtered_data['card_id'].isin(card_ids_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe32950",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1140626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each card_id used the bus in each day\n",
    "usage_counts = ORCA_2023.groupby(['card_id', 'business_date'])['stop_code'].count().reset_index()\n",
    "\n",
    "# Identify card_ids that used the bus only once\n",
    "card_ids_to_exclude = usage_counts[usage_counts == 0].index\n",
    "card_ids_to_exclude.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assigning origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18993633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each card_id used the bus in each day\n",
    "usage_counts = ORCA_2023.groupby(['card_id', 'business_date'])['stop_code'].count().reset_index()\n",
    "\n",
    "# Identify card_ids that used the bus only once\n",
    "card_ids_to_exclude = usage_counts[usage_counts == 2].index\n",
    "card_ids_to_exclude.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['device_dtm_pacific'] = pd.to_datetime(filtered_data['device_dtm_pacific'])\n",
    "filtered_data['device_time'] = filtered_data['device_dtm_pacific'].dt.time\n",
    "\n",
    "# Group by 'card_id', 'business_day', and 'txn_id' to identify the first trip (earliest time)\n",
    "first_trip = filtered_data.groupby(['card_id', 'business_date', 'txn_id'], as_index=False)['device_time'].min()\n",
    "\n",
    "# Extract the first stop_id as origin for each 'card_id' on each 'business_day'\n",
    "origin_data = filtered_data.groupby(['card_id', 'business_date'])['stop_id'].first().reset_index()\n",
    "\n",
    "# Print the data with origins\n",
    "print(origin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8743a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
